{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f07802c0-2284-4bdf-815d-bf2825a2b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43047\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "# # tài liệu \n",
    "# https://docs.langchain.com/oss/python/langchain/rag\n",
    "\n",
    "# # Nếu bạn thay đổi API keys hoặc project settings, chạy:\n",
    "# from langchain_core import utils\n",
    "# utils.get_env_var.cache_clear()\n",
    "# # Sau đó reload lại environment variables.\n",
    "\n",
    "!pip install -qU langchain-ollama\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# LANGSMITH_TRACING=\"true\" bật tính năng tracing để theo dõi và debug ứng dụng của bạn.\n",
    "# LANGSMITH_API_KEY xác thực với LangSmith.\n",
    "# Đây là công cụ monitoring và observability - giúp bạn xem logs, traces, và debug ứng dụng RAG sau khi chạy.\n",
    "# hữu ích cho development và debugging!\n",
    "\n",
    "\n",
    "\n",
    "#1. cài đặt các dependencies cần thiết cho RAG (Retrieval-Augmented Generation):\n",
    "# langchain: Package chính\n",
    "# langchain-text-splitters: Chia nhỏ documents thành chunks\n",
    "# langchain-community: Integrations cộng đồng\n",
    "# bs4 (BeautifulSoup4): Parse HTML/XML khi load documents từ web\n",
    "# ( bước chuẩn bị để xử lý và index documents.)\n",
    "\n",
    "# => !pip install langchain langchain-text-splitters langchain-community bs4\n",
    "\n",
    "#2. Embedding model: OllamaEmbeddings(model=\"gpt-oss\") để chuyển text thành vector\n",
    "\n",
    "# code khởi tạo embedding model từ Ollama sử dụng model gpt-oss\n",
    "# OllamaEmbeddings chuyển đổi text thành vector số (embeddings) để biểu diễn ý nghĩa ngữ nghĩa.\n",
    "# Các vector này dùng cho similarity search trong vector store.\n",
    "# Model gpt-oss chạy local qua Ollama, không cần API key.\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "#embeddings = OllamaEmbeddings(model=\"gpt-oss\") #  không hỗ trợ embeddings.\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\") # ollama pull nomic-embed-text\n",
    "\n",
    "\n",
    "#3. Vector store: InMemoryVectorStore để lưu embedding\n",
    "\n",
    "# Đây là code tạo một vector store trong bộ nhớ (in-memory) để lưu trữ embeddings.\n",
    "# InMemoryVectorStore là một vector database chạy trong RAM, không lưu trữ vĩnh viễn.\n",
    "# embeddings là model embedding bạn đã khởi tạo trước đó.\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "# vector store này sẽ dùng để tìm kiếm tương tự (similarity search) trên dữ liệu đã được vector hóa.\n",
    "# Phù hợp cho testing hoặc ứng dụng nhỏ, không cần persistence.\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "# # SoupStrainer là một công cụ của thư viện BeautifulSoup (bs4) giúp lọc và chỉ parse những phần HTML cụ thể thay vì toàn bộ trang web.\n",
    "# Dùng bs4.SoupStrainer để chỉ lấy nội dung quan trọng (post-title, post-header, post-content)\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")  # Load được bao nhiêu kí tự?\n",
    "\n",
    "print(docs[0].page_content[:500])\n",
    "#print(docs[0].page_content) # lấy ra toàn bộ nội dung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3ed3b90-0abd-4925-bad5-07761946a28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 63 sub-documents.\n",
      "['8fea4940-af74-4153-9c49-ef1d6f3347d4', 'd6de6e75-8f6f-45de-bbf4-d45e3917de37', '46124bd6-d390-45b6-8f7c-df11a5b7f3dc']\n",
      "* Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote. [{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}]\n",
      "* Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote. [{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}]\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (12c1bc37-683f-4b73-863d-28f7a0cc5cea)\n",
      " Call ID: 12c1bc37-683f-4b73-863d-28f7a0cc5cea\n",
      "  Args:\n",
      "    query: standard method for task decomposition work breakdown structure extensions common extensions of WBS\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (cd38f0b5-6883-450e-9aeb-fcad6a409255)\n",
      " Call ID: cd38f0b5-6883-450e-9aeb-fcad6a409255\n",
      "  Args:\n",
      "    query: extensions of chain of thought prompting tree of thoughts self consistency\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (a2608f82-d9d6-481c-a0da-cc1dcc1a0091)\n",
      " Call ID: a2608f82-d9d6-481c-a0da-cc1dcc1a0091\n",
      "  Args:\n",
      "    query: self consistency chain of thought extension\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The tool returned same content. Might need other sources. Let's search again.\n",
      "Tool Calls:\n",
      "  retrieve_context (e811dc45-f969-40f8-a564-40e259a4a3c4)\n",
      " Call ID: e811dc45-f969-40f8-a564-40e259a4a3c4\n",
      "  Args:\n",
      "    query: standard method for task decomposition chain of thought self consistency tree of thoughts\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (df5bcc1c-a16b-4ccf-8ce4-c4b24c896364)\n",
      " Call ID: df5bcc1c-a16b-4ccf-8ce4-c4b24c896364\n",
      "  Args:\n",
      "    query: Chain of Thought prompting task decomposition standard method\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (40276c9e-300b-4946-8cc5-ca13b65cc624)\n",
      " Call ID: 40276c9e-300b-4946-8cc5-ca13b65cc624\n",
      "  Args:\n",
      "    query: task decomposition chain of thought self consistency tree of thoughts other extensions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (a49ddef2-3dbe-4ca3-ba3e-b9a653f31343)\n",
      " Call ID: a49ddef2-3dbe-4ca3-ba3e-b9a653f31343\n",
      "  Args:\n",
      "    query: self consistency chain of thought prompting\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 3549}\n",
      "Content: Self-Reflection#\n",
      "Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\n",
      "ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\n",
      "The ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\n",
      "Thought: ...\n",
      "Action: ...\n",
      "Observation: ...\n",
      "... (Repeated many times)\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 3549}\n",
      "Content: Self-Reflection#\n",
      "Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\n",
      "ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\n",
      "The ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\n",
      "Thought: ...\n",
      "Action: ...\n",
      "Observation: ...\n",
      "... (Repeated many times)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Standard method for task decomposition**\n",
      "\n",
      "| Method | Year | Key idea | How it decomposes a task |\n",
      "|--------|------|----------|--------------------------|\n",
      "| **Chain‑of‑Thought (CoT)** | 2022 (Wei et al.) | Instruct the model to “think step‑by‑step” | The model writes a sequence of intermediate reasoning steps that break a complex problem into a chain of simpler sub‑problems. Each step is a natural‑language sentence that can be evaluated or used to produce the final answer. |\n",
      "\n",
      "CoT has become the de‑facto baseline for prompting large language models on anything that requires multi‑step reasoning (e.g., math, logic puzzles, planning, etc.). It is simple to use: add a prompt like “Let’s think step by step” or “First, … then …” and let the model generate the chain.\n",
      "\n",
      "---\n",
      "\n",
      "**Common extensions of Chain‑of‑Thought**\n",
      "\n",
      "| Extension | Year | What it adds | Typical use‑case |\n",
      "|-----------|------|--------------|------------------|\n",
      "| **Tree of Thoughts (ToT)** | 2023 (Yao et al.) | Generates *multiple* thoughts at each step, forming a tree. A search strategy (BFS/DFS) is applied to explore the tree, and a classifier or majority vote picks the best branch. | Problems where several alternative reasoning paths exist (e.g., combinatorial search, planning with branching). |\n",
      "| **Self‑Consistency** | 2022 (Wang et al.) | Runs CoT many times with stochastic sampling, then aggregates the final answers (e.g., majority vote). The idea is that correct reasoning paths will appear more often. | Improves accuracy on math and logic tasks where the model can produce many noisy CoT traces. |\n",
      "| **ReAct** | 2023 (Yao et al.) | Interleaves *reasoning* and *action* steps. The prompt alternates between “Thought: …”, “Action: …”, “Observation: …”. The model can call external tools (search, calculators, APIs) while reasoning. | Interactive tasks that require both internal reasoning and external API calls (e.g., web‑search, database queries). |\n",
      "| **Self‑Reflection / Self‑Correction** | 2023 (Yao et al.) | After an action, the model reflects on the outcome and can revise its earlier thoughts or actions. | Iterative debugging, multi‑round dialogue, or tasks that benefit from revisiting earlier decisions. |\n",
      "| **Chain‑of‑Thought with Retrieval (CoT‑R)** | 2023‑24 | Combines CoT with retrieval‑augmented generation: the model can fetch relevant documents or facts at each reasoning step. | Fact‑heavy reasoning (e.g., answering questions that need up‑to‑date knowledge). |\n",
      "| **Multi‑Modal CoT** | 2023‑24 | Extends CoT to handle visual or other modalities (e.g., “Let’s think step by step about the image”). | Tasks that involve image‑captioning, visual reasoning, or multimodal planning. |\n",
      "\n",
      "---\n",
      "\n",
      "### Quick‑start guide\n",
      "\n",
      "1. **Baseline CoT**  \n",
      "   ```text\n",
      "   Question: What is 12 × 13?\n",
      "   Let's think step by step.\n",
      "   ```\n",
      "   The model will output a chain of reasoning and then the answer.\n",
      "\n",
      "2. **Tree of Thoughts**  \n",
      "   ```text\n",
      "   Think of multiple ways to solve the problem.  \n",
      "   Thought 1: …  \n",
      "   Thought 2: …  \n",
      "   (Continue exploring branches)\n",
      "   ```\n",
      "\n",
      "3. **Self‑Consistency**  \n",
      "   ```text\n",
      "   Repeat the following 10 times:  \n",
      "   “Let’s think step by step.”  \n",
      "   (Collect all final answers and take the majority)\n",
      "   ```\n",
      "\n",
      "4. **ReAct**  \n",
      "   ```text\n",
      "   Thought: I need to find the capital of France.  \n",
      "   Action: Search(\"capital of France\")  \n",
      "   Observation: The search result says Paris.  \n",
      "   Thought: Therefore the answer is Paris.  \n",
      "   ```\n",
      "\n",
      "5. **Self‑Reflection**  \n",
      "   ```text\n",
      "   Thought: I think the answer is X.  \n",
      "   Action: Compute X.  \n",
      "   Observation: The result is wrong.  \n",
      "   Thought: I made a mistake; I should have used Y instead.  \n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "### Take‑away\n",
      "\n",
      "- **Chain‑of‑Thought** is the foundational, “plain‑text” way to break a problem into a linear chain of reasoning steps.  \n",
      "- Extensions add *branching*, *aggregation*, *tool‑use*, or *reflection* to handle more complex, interactive, or noisy reasoning scenarios.  \n",
      "- In practice, you can start with CoT, then layer on Self‑Consistency for higher accuracy, or switch to Tree of Thoughts / ReAct when the problem naturally involves branching or external calls.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")\n",
    "\n",
    "# dùng để lưu trữ và đánh chỉ mục (index) các tài liệu vào vector store.\n",
    "# Phương thức add_documents() nhúng (embed) nội dung của từng document split \n",
    "# và lưu vào vector store để sau này có thể tìm kiếm ngữ nghĩa (semantic search).\n",
    "# trả về danh sách các ID duy nhất cho mỗi document đã thêm, có thể dùng để xóa hoặc cập nhật sau này.\n",
    "# Đây là bước quan trọng trong giai đoạn Indexing của hệ thống RAG.\n",
    "\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "print(document_ids[:3])\n",
    "\n",
    "# Retrieval (Truy xuất)\n",
    "results = vector_store.similarity_search(\n",
    "    \"What is Task Decomposition?\",\n",
    "    k=2\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")\n",
    "\n",
    "# Generation (Tạo câu trả lời):\n",
    "\n",
    "#1. tạo một tool (công cụ) để truy xuất thông tin từ vector store.\n",
    "#2. Tạo agent kết hợp LLM + retrieval tool\n",
    "#3. Chạy agent để trả lời câu hỏi dựa trên context đã retrieve\n",
    "\n",
    "\n",
    "# Decorator @tool(response_format=\"content_and_artifact\") cấu hình tool trả về hai giá trị:\n",
    "#1. Content: Chuỗi văn bản đã được định dạng (gửi cho model)\n",
    "#2. Artifact: Danh sách tài liệu gốc (dùng cho xử lý sau, không gửi cho model)\n",
    "\n",
    "from langchain.tools import tool # Import thư viện để tạo công cụ (tool)\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\") # Decorator - đánh dấu hàm bên dưới là một tool.\n",
    "#response_format=\"content_and_artifact\" nghĩa là tool sẽ trả về 2 thứ:\n",
    "# content: Văn bản gửi cho model (LLM)\n",
    "# artifact: Dữ liệu thô (metadata) dùng cho ứng dụng, không gửi cho model\n",
    "\n",
    "# similarity_search là method của vector store dùng để tìm kiếm tài liệu tương tự (semantic search) dựa trên vector embeddings.\n",
    "# Cách hoạt động:\n",
    "#1. Nhận query text (câu hỏi)\n",
    "#2. Chuyển query thành vector embedding\n",
    "#3. So sánh với các vectors đã lưu trong store (dùng cosine similarity, euclidean distance...)\n",
    "#4. Trả về k documents gần nhất\n",
    "\n",
    "# Tham số chính:\n",
    "# query: Câu hỏi/text cần tìm\n",
    "# k: Số lượng kết quả trả về (mặc định thường là 4)\n",
    "# filter: Lọc theo metadata (tùy chọn)\n",
    "\n",
    "# k là số lượng documents (chunks) phù hợp nhất mà bạn muốn lấy về từ vector store.\n",
    "# Ví dụ đơn giản:\n",
    "# Bạn có 256 chunks về Hà Nội trong vector store\n",
    "# Bạn hỏi: \"Hà Nội có biệt danh gì?\"\n",
    "# Vector store tìm và xếp hạng 256 chunks theo độ liên quan\n",
    "# k=2 nghĩa là: Chỉ lấy 2 chunks liên quan nhất\n",
    "# k=5 nghĩa là: Lấy 5 chunks liên quan nhất\n",
    "# Tại sao cần k?\n",
    "\n",
    "# k nhỏ (2-3): Ít context, nhanh hơn, tập trung\n",
    "# k lớn (10+): Nhiều context, chậm hơn, có thể thêm noise\n",
    "# Thường dùng k=3 đến k=5 cho RAG.\n",
    "    \n",
    "def retrieve_context(query: str): # Định nghĩa hàm tên retrieve_context, nhận tham số query (câu truy vấn)\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\" # Mô tả công dụng của tool - giúp model hiểu khi nào cần dùng\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2) # Tìm kiếm 2 documents giống nhất với câu hỏi trong vector store\n",
    "    serialized = \"\\n\\n\".join( # Ghép nối các documents thành chuỗi văn bản dễ đọc (gửi cho model)\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs # Trả về 2 giá trị: văn bản (cho model) và documents gốc (cho ứng dụng)\n",
    "# Note:  \n",
    "# Model embeddings và model generation không cần giống nhau:\n",
    "\n",
    "# tích hợp nó vào agent. Tool này sẽ được gọi tự động khi agent cần truy xuất thông tin.\n",
    "#1. Tạo agent với create_agent() và truyền tool vào\n",
    "#2. Invoke agent với câu hỏi của người dùng\n",
    "#3. Agent sẽ tự động gọi tool khi cần và trả về câu trả lời\n",
    "\n",
    "# *************************\n",
    "\n",
    "# Import thư viện ChatOllama để sử dụng mô hình Ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "# Khởi tạo mô hình chat với tên \"gpt-oss\" và temperature=0 (để kết quả ổn định, không ngẫu nhiên)\n",
    "model = ChatOllama(model=\"gpt-oss\", temperature=0)\n",
    "# Import hàm create_agent để tạo agent\n",
    "from langchain.agents import create_agent\n",
    "# Định nghĩa danh sách các công cụ (tools) mà agent có thể sử dụng\n",
    "tools = [retrieve_context] \n",
    "# Tạo prompt hướng dẫn cho agent về cách sử dụng công cụ\n",
    "prompt = \"You have access to a tool that retrieves context. Use it to help answer queries.\"\n",
    "# Tạo agent với model, tools và system_prompt đã định nghĩa\n",
    "agent = create_agent(\n",
    "    model=model,              # Mô hình ngôn ngữ sẽ được sử dụng\n",
    "    tools=tools,              # Danh sách công cụ agent có thể gọi\n",
    "    system_prompt=prompt      # Hướng dẫn hệ thống cho agent\n",
    ")\n",
    "query = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "# ************************\n",
    "# Gọi agent với một tin nhắn từ người dùng\n",
    "# .invoke(): Đợi agent chạy xong hoàn toàn rồi mới trả về kết quả cuối cùng.\n",
    "\n",
    "# result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "# # In ra nội dung của tin nhắn cuối cùng trong kết quả (câu trả lời của agent)\n",
    "# print(result['messages'][-1].content)\n",
    "\n",
    "# ************************\n",
    "\n",
    "# .stream(): Trả về kết quả theo thời gian thực (real-time), cho phép bạn thấy từng bước agent đang làm gì\n",
    "# Mỗi event chứa toàn bộ state của graph sau mỗi bước:\n",
    "# event[\"messages\"]: Danh sách tất cả messages từ đầu đến hiện tại\n",
    "# event[\"messages\"][-1]: Message mới nhất (vừa được thêm vào)\n",
    "# .pretty_print(): Hiển thị message dễ đọc với format đẹp\n",
    "# TÀI LIỆU Streaming (https://docs.langchain.com/oss/python/langgraph/streaming)\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",):event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "# agent.stream(...): Chạy agent và trả về kết quả dần dần (không chờ hết)\n",
    "# {\"messages\": [{\"role\": \"user\", \"content\": query}]}: Input - tin nhắn từ user\n",
    "# stream_mode=\"values\": Trả về toàn bộ state sau mỗi bước (bao gồm tất cả messages)\n",
    "# for event in ...: Lặp qua từng event (mỗi bước agent thực hiện)\n",
    "# event[\"messages\"][-1]: Lấy message mới nhất trong state\n",
    "# .pretty_print(): In ra màn hình dễ đọc\n",
    "\n",
    "\n",
    "# Các loại messages bạn sẽ thấy:\n",
    "# Human Message: Câu hỏi của user\n",
    "# AI Message với tool_calls: Agent quyết định gọi tool nào\n",
    "# Tool Message: Kết quả từ tool\n",
    "# AI Message cuối: Câu trả lời cuối cùng\n",
    "\n",
    "# ************************\n",
    "\n",
    "# SAU ĐÓ:\n",
    "# 1. Đánh giá agent (Evaluation): Kiểm tra chất lượng câu trả lời, trajectory (đường đi của agent), và từng bước riêng lẻ\n",
    "\n",
    "# 2. Thêm memory/checkpointer: Lưu trữ lịch sử hội thoại để agent nhớ ngữ cảnh qua nhiều lượt tương tác\n",
    "\n",
    "# 3. Tùy chỉnh nâng cao: Thêm middleware, custom tools, hoặc xây dựng multi-agent system (như supervisor pattern)\n",
    "\n",
    "# 4. Deploy và monitor: Triển khai agent và theo dõi performance qua LangSmith\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75d592-b9ac-4210-9ef5-71c2f8571369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
